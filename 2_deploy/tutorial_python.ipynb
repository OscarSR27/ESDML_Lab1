{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f2067a",
   "metadata": {},
   "source": [
    "# MircoKWS deployment using TVM's Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28712a7",
   "metadata": {},
   "source": [
    "While the `tvmc` utility explained in `tutorial_tvmc.md` is very easy to use, in some situations it is more straightforward to interface with TVM directly via a Python script. While the tutorial in `tutorial_tvmc.md` contains a step by step guide on how to get started with TVM by compiling on the command line, this Jupyter notebook will introduce the TVMC Python API. It can be used analogously to the `tvmc` command line utility. More information can be found https://tvm.apache.org/docs/tutorial/tvmc_python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ebf2d8",
   "metadata": {},
   "source": [
    "Only the flow for generating kernels for an embedded device are covered at the moment. The used executor and features are aligned with the examples in `tutotial_tvmc.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37db34",
   "metadata": {},
   "source": [
    "## Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799e340",
   "metadata": {},
   "source": [
    "This tutorial is heavily inspired by the official \"microTVM with TFLite Models\" How-To in the TVM documentation (https://tvm.apache.org/docs/how_to/work_with_microtvm/micro_tflite.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a25e3",
   "metadata": {},
   "source": [
    "## Setting up the dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3805ae51",
   "metadata": {},
   "source": [
    "Please follow the instructions at the top of `install_tvm.md` to\n",
    "- Install required software\n",
    "- Setup and activate a virtual python environment\n",
    "- Install TVM\n",
    "  - via `tlcpack` python package, or\n",
    "  - by building it manually from source (See https://tvm.apache.org/docs/install/from_source.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bd80a",
   "metadata": {},
   "source": [
    "Make sure to activate the virtual environment before launching the jupyter kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65265f",
   "metadata": {},
   "source": [
    "The following cell is only required for custom TVM builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# sys.path.append(\"/PATH/TO/TVM/python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6a82f",
   "metadata": {},
   "source": [
    "Import Python dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e67250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import pathlib\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import tflite\n",
    "import tvm\n",
    "from tvm import relay, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae5e6a",
   "metadata": {},
   "source": [
    "## MicroKWS Flow using TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32d4f0",
   "metadata": {},
   "source": [
    "### Load and prepare the Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bab1d",
   "metadata": {},
   "source": [
    "First, define the path to the TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27f03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_MODEL = \"data/micro_kws_student_quantized.tflite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688dd31d",
   "metadata": {},
   "source": [
    "Next, load the file into a binary buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3cd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_buf = open(TFLITE_MODEL, \"rb\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d9784",
   "metadata": {},
   "source": [
    "Initialize the TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c5e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = tflite.Model.GetRootAsModel(tflite_model_buf, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cba2b8",
   "metadata": {},
   "source": [
    "Provide information on the input tensors (Name, DataType and Shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fecdb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = \"serving_default_input:0\"\n",
    "input_shape = (1, 1960)\n",
    "input_dtype = \"int8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ca073",
   "metadata": {},
   "source": [
    "Convert TFlite Model to Relay IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5784fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_tflite(\n",
    "    tflite_model, shape_dict={input_tensor: input_shape}, dtype_dict={input_tensor: input_dtype}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fce21",
   "metadata": {},
   "source": [
    "### Defining the runtime, target and executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0fc5f",
   "metadata": {},
   "source": [
    "The use target device is a generic MicroTVM target. We are using the CRT runtime in combination with the AoT executor as it is more lightweight compared to the full C++ runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d57522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = tvm.target.target.micro(\"host\")\n",
    "RUNTIME = tvm.relay.backend.Runtime(\"crt\", {\"system-lib\": False})\n",
    "EXECUTOR = tvm.relay.backend.Executor(\n",
    "    \"aot\", {\"interface-api\": \"c\", \"unpacked-api\": True, \"link-params\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b30470",
   "metadata": {},
   "source": [
    "### Define pass configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9e81e",
   "metadata": {},
   "source": [
    "These options will be passed to the `relay.build()` function in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47e3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"tir.disable_vectorize\": True,\n",
    "    \"tir.usmp.enable\": True,\n",
    "    \"tir.usmp.algorithm\": \"hill_climb\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b18c3",
   "metadata": {},
   "source": [
    "For more a detailed explanation of these options, see the `--pass-config` flags in `tutorial_tvmc.md`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042a238",
   "metadata": {},
   "source": [
    "### Apply Transformations to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f4db7",
   "metadata": {},
   "source": [
    "TFLite models typically use the `NHWC` format to store the weight of a convolutional layer. However, in some situations (especially when performing autotuning) a schedule using a `HCHW` layout can be more efficient. The following code, therefore, applies passes to the relay modules, which transform the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "690ff94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:31:01] /workspace/tvm/src/relay/transforms/convert_layout.cc:99: Warning: Desired layout(s) not specified for op: nn.max_pool2d\n",
      "[23:31:01] /workspace/tvm/src/relay/transforms/convert_layout.cc:99: Warning: Desired layout(s) not specified for op: nn.avg_pool2d\n",
      "[23:31:01] /workspace/tvm/src/relay/transforms/convert_layout.cc:99: Warning: Desired layout(s) not specified for op: nn.avg_pool2d\n"
     ]
    }
   ],
   "source": [
    "desired_layout = \"NCHW\"\n",
    "desired_layouts = {\n",
    "    \"nn.conv2d\": [desired_layout, \"default\"],\n",
    "    \"nn.conv2d_transpose\": [desired_layout, \"default\"],\n",
    "    \"qnn.conv2d\": [desired_layout, \"default\"],\n",
    "}\n",
    "\n",
    "# Convert the layout of the graph where possible.\n",
    "seq = transform.Sequential(\n",
    "    [\n",
    "        relay.transform.RemoveUnusedFunctions(),\n",
    "        relay.transform.ConvertLayout(desired_layouts),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with transform.PassContext(opt_level=3):\n",
    "    mod = seq(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9686d",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c9fb0",
   "metadata": {},
   "source": [
    "While this step looks pretty simple, it actually invoces the whole compilation pipeline provided by TVM. Depending on the complexity of the model and the enabled features, it might take a couple of seconds to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9146e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:32:01] /workspace/tvm/src/runtime/threading_backend.cc:338: Warning: more than two frequencies detected!\n",
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3, config=cfg):\n",
    "    module = relay.build(mod, target=TARGET, runtime=RUNTIME, executor=EXECUTOR, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada3045",
   "metadata": {},
   "source": [
    "### Export codegen artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b5862",
   "metadata": {},
   "source": [
    "For MicroTVM targets we are interested in the Model Library Format (MLF) artifact as it contains the sources required to build our target software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8e8a8a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gen/mlf.tar.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/almo/Windows/Users/Thien/Documents/MSNE/WS23_ESD4ML/assignment_lab_git/micro-kws/2_deploy/tutorial_python.ipynb Cell 40\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/almo/Windows/Users/Thien/Documents/MSNE/WS23_ESD4ML/assignment_lab_git/micro-kws/2_deploy/tutorial_python.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_library_format_tar_path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39mgen/mlf.tar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/almo/Windows/Users/Thien/Documents/MSNE/WS23_ESD4ML/assignment_lab_git/micro-kws/2_deploy/tutorial_python.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tvm\u001b[39m.\u001b[39;49mmicro\u001b[39m.\u001b[39;49mexport_model_library_format(module, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_library_format_tar_path\u001b[39m}\u001b[39;49;00m\u001b[39m.tar\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Programs/anaconda3/envs/esd/lib/python3.8/site-packages/tvm/micro/model_library_format.py:670\u001b[0m, in \u001b[0;36mexport_model_library_format\u001b[0;34m(mods, file_name)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    667\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDon\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt know how to export module of type \u001b[39m\u001b[39m{\u001b[39;00mmodules[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    668\u001b[0m     )\n\u001b[0;32m--> 670\u001b[0m _make_tar(tempdir\u001b[39m.\u001b[39;49mpath, file_name, modules)\n\u001b[1;32m    672\u001b[0m \u001b[39mreturn\u001b[39;00m file_name\n",
      "File \u001b[0;32m~/Programs/anaconda3/envs/esd/lib/python3.8/site-packages/tvm/micro/model_library_format.py:369\u001b[0m, in \u001b[0;36m_make_tar\u001b[0;34m(source_dir, tar_file_path, modules)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_tar\u001b[39m(source_dir, tar_file_path, modules):\n\u001b[1;32m    368\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a tar file from source_dir.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     \u001b[39mwith\u001b[39;00m tarfile\u001b[39m.\u001b[39;49mopen(tar_file_path, \u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m tar_f:\n\u001b[1;32m    371\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(tarinfo):\n\u001b[1;32m    372\u001b[0m             tarinfo\u001b[39m.\u001b[39muid \u001b[39m=\u001b[39m tarinfo\u001b[39m.\u001b[39mgid \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Programs/anaconda3/envs/esd/lib/python3.8/tarfile.py:1821\u001b[0m, in \u001b[0;36mTarFile.open\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m   1820\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mtaropen(name, mode, fileobj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1823\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mundiscernible mode\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programs/anaconda3/envs/esd/lib/python3.8/tarfile.py:1831\u001b[0m, in \u001b[0;36mTarFile.taropen\u001b[0;34m(cls, name, mode, fileobj, **kwargs)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1830\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmode must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1831\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(name, mode, fileobj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programs/anaconda3/envs/esd/lib/python3.8/tarfile.py:1646\u001b[0m, in \u001b[0;36mTarFile.__init__\u001b[0;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1645\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1646\u001b[0m     fileobj \u001b[39m=\u001b[39m bltn_open(name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mode)\n\u001b[1;32m   1647\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extfileobj \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gen/mlf.tar.tar'"
     ]
    }
   ],
   "source": [
    "model_library_format_tar_path = Path(\"gen/mlf.tar\")\n",
    "tvm.micro.export_model_library_format(module, f\"{model_library_format_tar_path}.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5649c23",
   "metadata": {},
   "source": [
    "### Optional: Use provided autotuning logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0ba60",
   "metadata": {},
   "source": [
    "Supply the tuning records (see tvm/data/ directory) like this and rebuild the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92726c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_records_file = Path(\"data/micro_kws_student_tuning_log_nchw_best.txt\")\n",
    "\n",
    "with tvm.autotvm.apply_history_best(tuning_records_file):\n",
    "    module_tuned = relay.build(\n",
    "        mod, target=TARGET, runtime=RUNTIME, executor=EXECUTOR, params=params\n",
    "    )\n",
    "\n",
    "model_library_format_tar_path_tuned = Path(\"gen/mlf_tuned\")\n",
    "tvm.micro.export_model_library_format(module_tuned, f\"{model_library_format_tar_path_tuned}.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d461e",
   "metadata": {},
   "source": [
    "Extract the MLF archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33043f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_library_format_tar_path_tuned.mkdir(exist_ok=True)\n",
    "tar = tarfile.open(f\"{model_library_format_tar_path_tuned}.tar\").extractall(\n",
    "    model_library_format_tar_path_tuned\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26071b61",
   "metadata": {},
   "source": [
    "### Support for physical hardware?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410ad86",
   "metadata": {},
   "source": [
    "MicroTVM supports a set of hardware boards which allows to directly compile, flash and run target software using a build model. However, the ESP32C3 target is currently not supported. Thus, the approach for the lab exercises is currently independent of the TVM framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
